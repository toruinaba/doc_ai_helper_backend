#!/usr/bin/env python3
"""
Function Callingã®å®Œå…¨ãƒ•ãƒ­ãƒ¼ã¨ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’æ¯”è¼ƒã™ã‚‹ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import aiohttp
import json


async def test_both_flows():
    """å®Œå…¨ãƒ•ãƒ­ãƒ¼ã¨ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’æ¯”è¼ƒ"""

    # ãƒ„ãƒ¼ãƒ«ãŒç¢ºå®Ÿã«å‘¼ã°ã‚Œã‚‹è³ªå•ã«å¤‰æ›´
    test_prompt = "Please calculate 127 times 943 using the calculation tool and provide me the result."

    # ãƒ†ã‚¹ãƒˆ1: å®Œå…¨ãƒ•ãƒ­ãƒ¼ï¼ˆcomplete_tool_flow=Trueï¼‰
    print("ğŸ”„ å®Œå…¨Function Callingãƒ•ãƒ­ãƒ¼ï¼ˆcomplete_tool_flow=Trueï¼‰")
    print("=" * 60)

    payload_complete = {
        "prompt": test_prompt,
        "provider": "openai",
        "complete_tool_flow": True,  # å®Œå…¨ãƒ•ãƒ­ãƒ¼
        "enable_tools": True,  # ä¿®æ­£: enable_function_calling -> enable_tools
        "tool_choice": "auto",
        "options": {"model": "azure-tk-gpt-4o", "temperature": 0.1, "max_tokens": 1000},
    }

    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://localhost:8000/api/v1/llm/query",
            json=payload_complete,
            headers={"Content-Type": "application/json"},
        ) as response:

            if response.status == 200:
                data = await response.json()
                print(f"ğŸ“ æœ€çµ‚å¿œç­”: {data.get('content', 'ãªã—')}")
                print(
                    f"ğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ: {data.get('tool_execution_results', 'ãªã—')}"
                )
                print(f"ğŸ¯ ãƒ¢ãƒ‡ãƒ«: {data.get('model', 'ãªã—')}")

                # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã®æœ‰ç„¡ã‚’ãƒ„ãƒ¼ãƒ«é–¢é€£ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ç¢ºèª
                tool_calls = data.get("tool_calls", [])
                print(f"ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«: {len(tool_calls) if tool_calls else 0}ä»¶")

                # original_tool_callsã®ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰
                orig_calls = data.get("original_tool_calls", [])
                print(f"ğŸ” å…ƒãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«: {len(orig_calls) if orig_calls else 0}ä»¶")

            else:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status}")

    print("\n" + "=" * 60)

    # ãƒ†ã‚¹ãƒˆ2: ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ãƒ­ãƒ¼ï¼ˆcomplete_tool_flow=Falseï¼‰
    print("ğŸ”„ ãƒ¬ã‚¬ã‚·ãƒ¼Function Callingãƒ•ãƒ­ãƒ¼ï¼ˆcomplete_tool_flow=Falseï¼‰")
    print("=" * 60)

    payload_legacy = {
        "prompt": test_prompt,
        "provider": "openai",
        "complete_tool_flow": False,  # ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ãƒ­ãƒ¼
        "enable_tools": True,  # ä¿®æ­£: enable_function_calling -> enable_tools
        "tool_choice": "auto",
        "options": {"model": "azure-tk-gpt-4o", "temperature": 0.1, "max_tokens": 1000},
    }

    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://localhost:8000/api/v1/llm/query",
            json=payload_legacy,
            headers={"Content-Type": "application/json"},
        ) as response:

            if response.status == 200:
                data = await response.json()
                print(f"ğŸ“ æœ€çµ‚å¿œç­”: {data.get('content', 'ãªã—')}")

                # ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ãƒ­ãƒ¼ã§ã¯ãƒ„ãƒ¼ãƒ«å®Ÿè¡ŒçµæœãŒæ˜ç¤ºçš„ã«è¿”ã•ã‚Œã‚‹
                tool_execution = data.get("tool_execution_results", [])
                if tool_execution:
                    print(f"ğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ: {len(tool_execution)}ä»¶")
                    for i, result in enumerate(tool_execution):
                        print(
                            f"  {i+1}. {result.get('function_name')}: {result.get('result')}"
                        )
                else:
                    print("ğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ: ãªã—")

                print(f"ğŸ¯ ãƒ¢ãƒ‡ãƒ«: {data.get('model', 'ãªã—')}")

            else:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status}")


if __name__ == "__main__":
    asyncio.run(test_both_flows())
