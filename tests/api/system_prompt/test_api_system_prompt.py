"""
ãƒ†ã‚¹ãƒˆç”¨ã®APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import httpx
import json
from typing import Dict, Any, Optional
from unittest.mock import patch
from fastapi.testclient import TestClient

from doc_ai_helper_backend.services.llm.providers.mock_service import MockLLMService
from doc_ai_helper_backend.services.llm.base import LLMServiceBase


def get_mock_llm_service() -> LLMServiceBase:
    """ãƒ†ã‚¹ãƒˆç”¨ã®MockLLMServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¿”ã™"""
    return MockLLMService(response_delay=0.1)


def test_context_aware_api():
    """APIçµŒç”±ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã‚¯ã‚¨ãƒªã‚’ãƒ†ã‚¹ãƒˆï¼ˆTestClientã‚’ä½¿ç”¨ï¼‰"""

    # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä¾å­˜é–¢æ•°ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    from doc_ai_helper_backend.main import app
    from doc_ai_helper_backend.api.dependencies import get_llm_service

    # ä¾å­˜é–¢æ•°ã‚’ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã«ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    app.dependency_overrides[get_llm_service] = get_mock_llm_service

    try:
        client = TestClient(app)

        # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        request_data = {
            "prompt": "ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¤ã„ã¦ç°¡å˜ã«èª¬æ˜ã—ã¦ãã ã•ã„",
            "repository_context": {
                "service": "github",
                "owner": "microsoft",
                "repo": "vscode",
                "ref": "main",
                "current_path": "README.md",
                "base_url": "https://github.com/microsoft/vscode",
            },
            "document_metadata": {
                "title": "Visual Studio Code",
                "type": "markdown",
                "filename": "README.md",
                "file_size": 5120,
                "language": "en",
            },
            "document_content": """# Visual Studio Code

Visual Studio Code is a lightweight but powerful source code editor which runs on your desktop and is available for Windows, macOS and Linux. It comes with built-in support for JavaScript, TypeScript and Node.js and has a rich ecosystem of extensions for other languages and runtimes (such as C++, C#, Java, Python, PHP, Go, .NET).

## Features

- IntelliSense
- Debugging
- Built-in Git support
- Extensions

Get started with the [introductory videos](https://code.visualstudio.com/docs/getstarted/introvideos).
""",
            "system_prompt_template": "contextual_document_assistant_ja",
            "include_document_in_system_prompt": True,
            "options": {"model": "mock", "temperature": 0.7},  # ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
        }

        print("=== APIçµŒç”±ã§ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ ===")
        print(f"é€ä¿¡ãƒ‡ãƒ¼ã‚¿:")
        print(f"  - prompt: {request_data['prompt']}")
        print(
            f"  - repository: {request_data['repository_context']['owner']}/{request_data['repository_context']['repo']}"
        )
        print(f"  - document: {request_data['repository_context']['current_path']}")
        print(f"  - system_prompt_template: {request_data['system_prompt_template']}")
        print(
            f"  - include_document_in_system_prompt: {request_data['include_document_in_system_prompt']}"
        )
        print(f"  - options.model: {request_data['options']['model']}")
        print()

        response = client.post("/api/v1/llm/query", json=request_data)

        print(f"HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")

        if response.status_code == 200:
            result = response.json()
            print("âœ… æˆåŠŸ:")
            print(f"  - content: {result.get('content', '')[:200]}...")
            print(f"  - model: {result.get('model', 'N/A')}")
            print(f"  - provider: {result.get('provider', 'N/A')}")
            print(f"  - usage: {result.get('usage', {})}")

            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä½¿ç”¨ã•ã‚ŒãŸã‹ã‚’ãƒã‚§ãƒƒã‚¯
            content = result.get("content", "")
            if "microsoft/vscode" in content or "Visual Studio Code" in content:
                print("âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«åæ˜ ã•ã‚Œã¦ã„ã¾ã™")
                return True
            else:
                print(
                    "âš ï¸  ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«åæ˜ ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                )
                print(f"     ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹: {content}")
                return False

        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            print(f"ã‚¨ãƒ©ãƒ¼å†…å®¹: {response.text}")
            return False

    finally:
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã‚’ã‚¯ãƒªã‚¢
        app.dependency_overrides.clear()


def test_minimal_context_api():
    """æœ€å°é™ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ†ã‚¹ãƒˆï¼ˆTestClientã‚’ä½¿ç”¨ï¼‰"""

    # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä¾å­˜é–¢æ•°ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    from doc_ai_helper_backend.main import app
    from doc_ai_helper_backend.api.dependencies import get_llm_service

    # ä¾å­˜é–¢æ•°ã‚’ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã«ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    app.dependency_overrides[get_llm_service] = get_mock_llm_service

    try:
        client = TestClient(app)

        request_data = {
            "prompt": "ã“ã‚“ã«ã¡ã¯",
            "repository_context": {
                "service": "github",
                "owner": "test",
                "repo": "minimal",
                "ref": "main",
            },
            "system_prompt_template": "minimal_context_ja",
            "include_document_in_system_prompt": True,
            "options": {"model": "mock"},
        }

        print("\n=== æœ€å°é™ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã®ãƒ†ã‚¹ãƒˆ ===")
        print(f"é€ä¿¡ãƒ‡ãƒ¼ã‚¿:")
        print(f"  - prompt: {request_data['prompt']}")
        print(
            f"  - repository: {request_data['repository_context']['owner']}/{request_data['repository_context']['repo']}"
        )
        print(f"  - system_prompt_template: {request_data['system_prompt_template']}")
        print(f"  - options.model: {request_data['options']['model']}")
        print()

        response = client.post("/api/v1/llm/query", json=request_data)

        print(f"HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")

        if response.status_code == 200:
            result = response.json()
            print("âœ… æˆåŠŸ:")
            print(f"  - content: {result.get('content', '')}")
            print(f"  - model: {result.get('model', 'N/A')}")

            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä½¿ç”¨ã•ã‚ŒãŸã‹ã‚’ãƒã‚§ãƒƒã‚¯
            content = result.get("content", "")
            if "test/minimal" in content:
                print("âœ… æœ€å°é™ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«åæ˜ ã•ã‚Œã¦ã„ã¾ã™")
                return True
            else:
                print(
                    "âš ï¸  ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«åæ˜ ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                )
                print(f"     ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹: {content}")
                return False

        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            print(f"ã‚¨ãƒ©ãƒ¼å†…å®¹: {response.text}")
            return False

    finally:
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã‚’ã‚¯ãƒªã‚¢
        app.dependency_overrides.clear()


def test_without_context():
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã§ã®ãƒ†ã‚¹ãƒˆï¼ˆå¾“æ¥ã®ã‚¯ã‚¨ãƒªã€TestClientã‚’ä½¿ç”¨ï¼‰"""

    # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä¾å­˜é–¢æ•°ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    from doc_ai_helper_backend.main import app
    from doc_ai_helper_backend.api.dependencies import get_llm_service

    # ä¾å­˜é–¢æ•°ã‚’ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã«ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    app.dependency_overrides[get_llm_service] = get_mock_llm_service

    try:
        client = TestClient(app)

        request_data = {
            "prompt": "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ",
            "include_document_in_system_prompt": False,
            "options": {"model": "mock"},
        }

        print("\n=== ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã§ã®ãƒ†ã‚¹ãƒˆ ===")
        print(f"é€ä¿¡ãƒ‡ãƒ¼ã‚¿:")
        print(f"  - prompt: {request_data['prompt']}")
        print(
            f"  - include_document_in_system_prompt: {request_data['include_document_in_system_prompt']}"
        )
        print(f"  - options.model: {request_data['options']['model']}")
        print()

        response = client.post("/api/v1/llm/query", json=request_data)

        print(f"HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")

        if response.status_code == 200:
            result = response.json()
            print("âœ… æˆåŠŸ:")
            print(f"  - content: {result.get('content', '')}")
            print(f"  - model: {result.get('model', 'N/A')}")
            return True

        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            print(f"ã‚¨ãƒ©ãƒ¼å†…å®¹: {response.text}")
            return False

    finally:
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã‚’ã‚¯ãƒªã‚¢
        app.dependency_overrides.clear()


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš€ APIçµŒç”±ã§ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")

    success_count = 0
    total_tests = 3

    if test_context_aware_api():
        success_count += 1

    if test_minimal_context_api():
        success_count += 1

    if test_without_context():
        success_count += 1

    print(f"\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†: {success_count}/{total_tests} æˆåŠŸ")

    if success_count == total_tests:
        print("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
    else:
        print("âš ï¸  ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    main()
