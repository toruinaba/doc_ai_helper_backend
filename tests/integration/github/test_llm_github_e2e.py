#!/usr/bin/env python3
"""
LLMçµŒç”±GitHub MCP E2Eãƒ†ã‚¹ãƒˆ
å®Ÿéš›ã®LLMãŒFunction Callingã§MCP GitHub toolsã‚’å‘¼ã³å‡ºã™E2Eãƒ†ã‚¹ãƒˆã§ã™
"""

import asyncio
import json
import os
from typing import Dict, Any, Optional
from doc_ai_helper_backend.services.llm.factory import LLMServiceFactory
from doc_ai_helper_backend.services.llm.utils import FunctionRegistry
from doc_ai_helper_backend.models.repository_context import RepositoryContext
from doc_ai_helper_backend.services.mcp.server import DocumentAIHelperMCPServer
from doc_ai_helper_backend.services.mcp.function_adapter import MCPFunctionAdapter


class E2ETestConfig:
    """E2Eãƒ†ã‚¹ãƒˆè¨­å®š"""
    def __init__(self):
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.openai_base_url = os.getenv('OPENAI_BASE_URL')
        self.github_token = os.getenv('GITHUB_TOKEN')
        self.test_repository = os.getenv('TEST_GITHUB_REPOSITORY', 'test-owner/test-repo')
        
    def is_valid(self) -> bool:
        """è¨­å®šãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        return bool(self.openai_api_key and self.github_token)
    
    def print_status(self):
        """è¨­å®šçŠ¶æ³ã‚’è¡¨ç¤º"""
        print("ğŸ”§ E2E ãƒ†ã‚¹ãƒˆè¨­å®šç¢ºèª:")
        print(f"   OpenAI API Key: {'âœ… è¨­å®šæ¸ˆã¿' if self.openai_api_key else 'âŒ æœªè¨­å®š'}")
        print(f"   OpenAI Base URL: {self.openai_base_url or 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ'}")
        print(f"   GitHub Token: {'âœ… è¨­å®šæ¸ˆã¿' if self.github_token else 'âŒ æœªè¨­å®š'}")
        print(f"   ãƒ†ã‚¹ãƒˆãƒªãƒã‚¸ãƒˆãƒª: {self.test_repository}")


async def test_llm_github_issue_creation():
    """LLMçµŒç”±ã§ã®GitHub Issueä½œæˆE2Eãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ LLMçµŒç”± GitHub Issueä½œæˆ E2Eãƒ†ã‚¹ãƒˆ")
    print("=" * 55)
    
    config = E2ETestConfig()
    config.print_status()
    
    if not config.is_valid():
        print("\nâŒ å¿…è¦ãªç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("   å¿…è¦ãªç’°å¢ƒå¤‰æ•°:")
        print("   - OPENAI_API_KEY: OpenAI APIã‚­ãƒ¼")
        print("   - GITHUB_TOKEN: GitHub Personal Access Token")
        print("   - TEST_GITHUB_REPOSITORY: ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒªãƒã‚¸ãƒˆãƒª (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
        return False
    
    print("\n" + "="*55)
    
    try:
        # 1. LLMã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
        print("1ï¸âƒ£ LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–...")
        llm_service = LLMServiceFactory.create(
            provider='openai',
            api_key=config.openai_api_key,
            base_url=config.openai_base_url,
            default_model='azure-tk-gpt-4o'  # .envã‹ã‚‰å–å¾—
        )
        print("   âœ… LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†")
        
        # 2. Function Registryã®è¨­å®š
        print("\n2ï¸âƒ£ Function Registryè¨­å®š...")
        function_registry = FunctionRegistry()
        
        # ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
        owner, repo = config.test_repository.split('/', 1)
        repository_context = RepositoryContext(
            repo=repo,
            owner=owner,
            service="github",
            ref="main"
        )
        
        # GitHub toolsã‚’ç™»éŒ²
        from doc_ai_helper_backend.services.mcp.function_adapter import MCPFunctionAdapter
        adapter = MCPFunctionAdapter()
        
        # GitHubé–¢æ•°ã‚’ç™»éŒ²
        github_functions = await adapter.get_available_functions()
        github_tool_functions = [f for f in github_functions if f.get('name', '').startswith('create_github')]
        
        for func in github_tool_functions:
            function_registry.register_function(func)
        
        print(f"   âœ… {len(github_tool_functions)}å€‹ã®GitHubé–¢æ•°ã‚’ç™»éŒ²")
        
        # 3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
        print(f"\nâš ï¸  ãƒªãƒã‚¸ãƒˆãƒª '{config.test_repository}' ã«å®Ÿéš›ã«Issueã‚’ä½œæˆã—ã¾ã™")
        confirm = input("   ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ").strip().lower()
        
        if confirm not in ['yes', 'y']:
            print("âŒ ãƒ†ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return False
        
        # 4. LLMã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        print("\n3ï¸âƒ£ LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ...")
        
        system_prompt = f"""
ã‚ãªãŸã¯ GitHub Issue ã‚’ä½œæˆã™ã‚‹å°‚é–€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {config.test_repository}

åˆ©ç”¨å¯èƒ½ãªé–¢æ•°:
- create_github_issue: GitHub Issue ã‚’ä½œæˆã—ã¾ã™

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«å¿œã˜ã¦ã€é©åˆ‡ãª Issue ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯æ—¥æœ¬èªã§è¡Œã„ã€ä½œæˆã•ã‚ŒãŸIssueã®è©³ç´°ã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚
"""
        
        user_prompt = """
ä»¥ä¸‹ã®å†…å®¹ã§GitHub Issueã‚’ä½œæˆã—ã¦ãã ã•ã„:

ã‚¿ã‚¤ãƒˆãƒ«: ğŸ¤– LLM E2E ãƒ†ã‚¹ãƒˆ - è‡ªå‹•ä½œæˆIssue
èª¬æ˜: 
- ã“ã‚Œã¯LLMçµŒç”±ã®E2Eãƒ†ã‚¹ãƒˆã§ä½œæˆã•ã‚ŒãŸIssueã§ã™
- Function Callingã®å‹•ä½œç¢ºèªã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™
- MCP GitHub Toolsã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆã§ã™
- ç¢ºèªå¾Œã€ã“ã®Issueã¯å‰Šé™¤ã—ã¦ã„ãŸã ã„ã¦æ§‹ã„ã¾ã›ã‚“

ãƒ©ãƒ™ãƒ«: ["e2e-test", "llm-generated", "auto-created"]
"""
        
        print("   âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")
        
        # 5. LLMã¸ã®å•ã„åˆã‚ã›ï¼ˆFunction Callingä»˜ãï¼‰
        print("\n4ï¸âƒ£ LLM Function Callingå®Ÿè¡Œ...")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’LLMã«æ³¨å…¥
        context_data = {
            "repository_context": repository_context.model_dump(),
            "github_token": config.github_token
        }
        
        query_options = {
            "model": "azure-tk-gpt-4o",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "functions": function_registry.get_all_functions(),
            "function_call": "auto",
            "context": context_data,
            "temperature": 0.1
        }
        
        print("   ğŸ“¤ LLMã¸å•ã„åˆã‚ã›ä¸­...")
        
        result = await llm_service.query(
            prompt="",  # messagesã§æŒ‡å®šæ¸ˆã¿
            options=query_options
        )
        
        print("   âœ… LLMå¿œç­”å—ä¿¡å®Œäº†")
        
        # 6. çµæœã®è§£æã¨è¡¨ç¤º
        print("\n5ï¸âƒ£ çµæœè§£æ...")
        
        if hasattr(result, 'function_calls') and result.function_calls:
            print(f"   ğŸ”§ Function Callå®Ÿè¡Œ: {len(result.function_calls)}ä»¶")
            
            for i, call in enumerate(result.function_calls, 1):
                print(f"   ğŸ“‹ Call {i}: {call.get('name', 'unknown')}")
                if call.get('result'):
                    try:
                        call_result = json.loads(call['result'])
                        if call_result.get('success'):
                            if 'issue_info' in call_result:
                                issue_info = call_result['issue_info']
                                print(f"      âœ… Issue #{issue_info.get('number')} ä½œæˆæˆåŠŸ")
                                print(f"      ğŸ”— URL: {issue_info.get('url')}")
                            print(f"      ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {call_result.get('message', 'N/A')}")
                        else:
                            print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {call_result.get('error', 'Unknown error')}")
                    except json.JSONDecodeError:
                        print(f"      ğŸ“„ Raw result: {call['result'][:100]}...")
        
        # LLMã®æœ€çµ‚å¿œç­”
        print(f"\n6ï¸âƒ£ LLMæœ€çµ‚å¿œç­”:")
        print(f"   ğŸ’¬ {result.content}")
        
        print(f"\nğŸ‰ E2Eãƒ†ã‚¹ãƒˆå®Œäº†!")
        return True
        
    except Exception as e:
        print(f"\nâŒ E2Eãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_llm_github_permissions_check():
    """LLMçµŒç”±ã§ã®GitHubæ¨©é™ç¢ºèªãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*55)
    print("ğŸ” LLMçµŒç”± GitHubæ¨©é™ç¢ºèªãƒ†ã‚¹ãƒˆ")
    print("=" * 55)
    
    config = E2ETestConfig()
    
    if not config.is_valid():
        print("âŒ ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    
    try:
        # LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        llm_service = LLMServiceFactory.create(
            provider='openai',
            api_key=config.openai_api_key,
            base_url=config.openai_base_url
        )
        
        # Function Registryè¨­å®š
        function_registry = FunctionRegistry()
        
        # ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        owner, repo = config.test_repository.split('/', 1)
        repository_context = RepositoryContext(
            repo=repo,
            owner=owner,
            service="github",
            ref="main"
        )
        
        # GitHubæ¨©é™ç¢ºèªé–¢æ•°ã‚’ç™»éŒ²
        from doc_ai_helper_backend.services.mcp.function_adapter import MCPFunctionAdapter
        adapter = MCPFunctionAdapter()
        
        github_functions = await adapter.get_available_functions()
        permissions_function = [f for f in github_functions if f.get('name') == 'check_github_repository_permissions']
        
        for func in permissions_function:
            function_registry.register_function(func)
        
        # LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_prompt = f"""
ã‚ãªãŸã¯GitHubãƒªãƒã‚¸ãƒˆãƒªã®æ¨©é™ç¢ºèªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {config.test_repository}

åˆ©ç”¨å¯èƒ½ãªé–¢æ•°:
- check_github_repository_permissions: ãƒªãƒã‚¸ãƒˆãƒªã®æ¨©é™ã‚’ç¢ºèªã—ã¾ã™

ãƒªãƒã‚¸ãƒˆãƒªã®æ¨©é™ã‚’ç¢ºèªã—ã¦ã€çµæœã‚’æ—¥æœ¬èªã§å ±å‘Šã—ã¦ãã ã•ã„ã€‚
"""
        
        user_prompt = "ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã®æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
        context_data = {
            "repository_context": repository_context.model_dump(),
            "github_token": config.github_token
        }
        
        query_options = {
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "functions": function_registry.get_all_functions(),
            "function_call": "auto",
            "context": context_data,
            "temperature": 0.1
        }
        
        print("ğŸ“¤ æ¨©é™ç¢ºèªå®Ÿè¡Œä¸­...")
        
        result = await llm_service.query(
            prompt="",
            options=query_options
        )
        
        print("ğŸ“Š æ¨©é™ç¢ºèªçµæœ:")
        if hasattr(result, 'function_calls') and result.function_calls:
            for call in result.function_calls:
                if call.get('result'):
                    try:
                        call_result = json.loads(call['result'])
                        if call_result.get('success'):
                            permissions = call_result.get('permissions', {})
                            print(f"   âœ… æ¨©é™ç¢ºèªæˆåŠŸ")
                            print(f"   ğŸ“‹ Issueä½œæˆ: {'âœ…' if permissions.get('issues') else 'âŒ'}")
                            print(f"   ğŸ“‹ PRä½œæˆ: {'âœ…' if permissions.get('pull_requests') else 'âŒ'}")
                            print(f"   ğŸ“‹ Pushæ¨©é™: {'âœ…' if permissions.get('push') else 'âŒ'}")
                        else:
                            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {call_result.get('error')}")
                    except json.JSONDecodeError:
                        print(f"   ğŸ“„ Raw: {call['result'][:100]}...")
        
        print(f"ğŸ’¬ LLMå¿œç­”: {result.content}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨©é™ç¢ºèªãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


async def test_readme_improvement_flow():
    """READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼E2Eãƒ†ã‚¹ãƒˆ - READMEã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åŸºã«æ”¹å–„Issueã‚’ä½œæˆ"""
    print("\n" + "="*55)
    print("ğŸ“– READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼ E2Eãƒ†ã‚¹ãƒˆ")
    print("=" * 55)
    
    config = E2ETestConfig()
    
    if not config.is_valid():
        print("âŒ ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    
    try:
        # 1. LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        print("1ï¸âƒ£ LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–...")
        llm_service = LLMServiceFactory.create(
            provider='openai',
            api_key=config.openai_api_key,
            base_url=config.openai_base_url,
            default_model='azure-tk-gpt-4o'
        )
        print("   âœ… LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†")
        
        # 2. Function Registryè¨­å®š
        print("2ï¸âƒ£ Function Registryè¨­å®š...")
        function_registry = FunctionRegistry()
        
        # ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        owner, repo = config.test_repository.split('/', 1)
        repository_context = RepositoryContext(
            repo=repo,
            owner=owner,
            service="github",
            ref="main"
        )
        
        # GitHubé–¢æ•°ã‚’ç™»éŒ²
        from doc_ai_helper_backend.services.mcp.function_adapter import MCPFunctionAdapter
        adapter = MCPFunctionAdapter()
        
        github_functions = await adapter.get_available_functions()
        github_tool_functions = [f for f in github_functions if f.get('name', '').startswith('create_github')]
        
        for func in github_tool_functions:
            function_registry.register_function(func)
        
        print(f"   âœ… {len(github_tool_functions)}å€‹ã®GitHubé–¢æ•°ã‚’ç™»éŒ²")
        
        # 3. ã‚µãƒ³ãƒ—ãƒ«READMEã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆåˆ†æå¯¾è±¡ï¼‰
        print("3ï¸âƒ£ README ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æº–å‚™...")
        
        sample_readme = """# My Project

This is a simple project.

## Setup

Run the following commands:

```bash
npm install
npm start
```

## Usage

Use the application.

Contact: email@example.com
"""
        
        print("   âœ… ã‚µãƒ³ãƒ—ãƒ«READMEã‚³ãƒ³ãƒ†ãƒ³ãƒ„æº–å‚™å®Œäº†")
        
        # 4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
        print(f"\nâš ï¸  ãƒªãƒã‚¸ãƒˆãƒª '{config.test_repository}' ã«READMEæ”¹å–„Issueã‚’ä½œæˆã—ã¾ã™")
        confirm = input("   ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ").strip().lower()
        
        if confirm not in ['yes', 'y']:
            print("âŒ ãƒ†ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return False
        
        # 5. LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆREADMEã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ³¨å…¥ï¼‰
        print("4ï¸âƒ£ READMEæ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ...")
        
        system_prompt = f"""
ã‚ãªãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ”¹å–„ã®å°‚é–€å®¶ã§ã™ã€‚
ãƒªãƒã‚¸ãƒˆãƒª: {config.test_repository}

ç¾åœ¨ã®README.mdãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹:
```markdown
{sample_readme}
```

ã‚ãªãŸã®å½¹å‰²:
1. æä¾›ã•ã‚ŒãŸREADMEã®å†…å®¹ã‚’åˆ†æ
2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æ”¹å–„è¦æ±‚ã‚’ç†è§£
3. å…·ä½“çš„ã§å®Ÿç”¨çš„ãªæ”¹å–„ææ¡ˆã‚’GitHub Issueã¨ã—ã¦ä½œæˆ

åˆ©ç”¨å¯èƒ½ãªé–¢æ•°:
- create_github_issue: æ”¹å–„ææ¡ˆã‚’GitHub Issueã¨ã—ã¦ä½œæˆ

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«åŸºã¥ã„ã¦ã€READMEã®å…·ä½“çš„ãªæ”¹å–„ç‚¹ã‚’åˆ†æã—ã€
é©åˆ‡ãªã‚¿ã‚¤ãƒˆãƒ«ã€è©³ç´°ãªèª¬æ˜ã€é–¢é€£ãƒ©ãƒ™ãƒ«ã‚’å«ã‚€Issueã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
        
        user_prompt = """
ã“ã®READMEã¯æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¦ã€æ–°ã—ã„é–‹ç™ºè€…ãŒç†è§£ã—ã«ãã„ã¨æ€ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®æ”¹å–„ç‚¹ã‚’å«ã‚€GitHub Issueã‚’ä½œæˆã—ã¦ãã ã•ã„:

- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„ã¨æ¦‚è¦ãŒä¸æ˜
- å‰ææ¡ä»¶ï¼ˆNode.jsãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©ï¼‰ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ãªã„  
- ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ãŒç°¡æ½”ã™ãã‚‹
- ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜ãŒæ›–æ˜§
- ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±ãŒãªã„
- è²¢çŒ®æ–¹æ³•ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ãªã„

é–‹ç™ºè€…ã«ã¨ã£ã¦è¦ªåˆ‡ã§å®Ÿç”¨çš„ãªREADMEã«ã™ã‚‹ãŸã‚ã®æ”¹å–„ææ¡ˆã‚’Issueã¨ã—ã¦æŠ•ç¨¿ã—ã¦ãã ã•ã„ã€‚
"""
        
        print("   âœ… READMEæ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†")
        
        # 6. LLM Function Callingå®Ÿè¡Œ
        print("5ï¸âƒ£ READMEæ”¹å–„åˆ†æ & Issueä½œæˆå®Ÿè¡Œ...")
        
        context_data = {
            "repository_context": repository_context.model_dump(),
            "github_token": config.github_token,
            "readme_content": sample_readme
        }
        
        query_options = {
            "model": "azure-tk-gpt-4o",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "functions": function_registry.get_all_functions(),
            "function_call": "auto",
            "context": context_data,
            "temperature": 0.3  # å‰µé€ çš„ãªæ”¹å–„ææ¡ˆã®ãŸã‚å°‘ã—é«˜ã‚
        }
        
        print("   ğŸ“– READMEåˆ†æä¸­...")
        print("   ğŸ” æ”¹å–„ç‚¹ã®ç‰¹å®šä¸­...")
        print("   ğŸ“ Issueä½œæˆä¸­...")
        
        result = await llm_service.query(
            prompt="",  # messagesã§æŒ‡å®šæ¸ˆã¿
            options=query_options
        )
        
        print("   âœ… READMEæ”¹å–„åˆ†æå®Œäº†")
        
        # 7. çµæœè§£æã¨è¡¨ç¤º
        print("6ï¸âƒ£ READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼çµæœè§£æ...")
        
        success = False
        issue_url = None
        
        if hasattr(result, 'function_calls') and result.function_calls:
            print(f"   ğŸ”§ Function Callå®Ÿè¡Œ: {len(result.function_calls)}ä»¶")
            
            for i, call in enumerate(result.function_calls, 1):
                print(f"   ğŸ“‹ Call {i}: {call.get('name', 'unknown')}")
                if call.get('result'):
                    try:
                        call_result = json.loads(call['result'])
                        if call_result.get('success'):
                            success = True
                            if 'issue_info' in call_result:
                                issue_info = call_result['issue_info']
                                issue_url = issue_info.get('url')
                                print(f"      âœ… READMEæ”¹å–„Issue #{issue_info.get('number')} ä½œæˆæˆåŠŸ")
                                print(f"      ğŸ“š ã‚¿ã‚¤ãƒˆãƒ«: {issue_info.get('title', 'N/A')}")
                                print(f"      ğŸ”— URL: {issue_url}")
                                print(f"      ğŸ·ï¸  ãƒ©ãƒ™ãƒ«: {issue_info.get('labels', [])}")
                            print(f"      ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {call_result.get('message', 'N/A')}")
                        else:
                            print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {call_result.get('error', 'Unknown error')}")
                    except json.JSONDecodeError:
                        print(f"      ğŸ“„ Raw result: {call['result'][:100]}...")
        
        # 8. LLMã®æ”¹å–„åˆ†æçµæœè¡¨ç¤º
        print(f"\n7ï¸âƒ£ LLMã«ã‚ˆã‚‹READMEæ”¹å–„åˆ†æçµæœ:")
        print(f"   ğŸ’­ {result.content}")
        
        # 9. ãƒ•ãƒ­ãƒ¼æˆåŠŸç¢ºèª
        if success and issue_url:
            print(f"\nğŸ‰ READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼æˆåŠŸ!")
            print(f"   ğŸ“– READMEå†…å®¹ã®åˆ†æå®Œäº†")
            print(f"   ğŸ” æ”¹å–„ç‚¹ã®ç‰¹å®šå®Œäº†")  
            print(f"   ğŸ“ GitHub Issueä½œæˆå®Œäº†")
            print(f"   ğŸ”— ä½œæˆã•ã‚ŒãŸIssue: {issue_url}")
            print(f"   âœ¨ æ–°ã—ã„é–‹ç™ºè€…ã«ã¨ã£ã¦ç†è§£ã—ã‚„ã™ã„READMEã¸ã®æ”¹å–„ææ¡ˆãŒæŠ•ç¨¿ã•ã‚Œã¾ã—ãŸ")
        else:
            print(f"\nâš ï¸  READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            print(f"   ğŸ“Š Issueä½œæˆ: {'âœ…' if success else 'âŒ'}")
        
        return success
        
    except Exception as e:
        print(f"\nâŒ READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ãƒ¡ã‚¤ãƒ³E2Eãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª LLMçµŒç”± GitHub MCP E2Eãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("=" * 60)
    
    # ç’°å¢ƒç¢ºèª
    config = E2ETestConfig()
    if not config.is_valid():
        print("\nğŸ“ ç’°å¢ƒå¤‰æ•°è¨­å®šä¾‹:")
        print("   PowerShell:")
        print("   $env:OPENAI_API_KEY='sk-your-key-here'")
        print("   $env:GITHUB_TOKEN='ghp-your-token-here'")
        print("   $env:TEST_GITHUB_REPOSITORY='your-username/your-test-repo'")
        return
    
    results = []
    
    # ãƒ†ã‚¹ãƒˆ1: GitHubæ¨©é™ç¢ºèª
    print("\nğŸ” ãƒ†ã‚¹ãƒˆ1: GitHubæ¨©é™ç¢ºèª")
    result1 = await test_llm_github_permissions_check()
    results.append(("æ¨©é™ç¢ºèª", result1))
    
    # ãƒ†ã‚¹ãƒˆ2: READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼
    print("\nğŸ“– ãƒ†ã‚¹ãƒˆ2: READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼")
    result2 = await test_readme_improvement_flow()
    results.append(("READMEæ”¹å–„ãƒ•ãƒ­ãƒ¼", result2))
    
    # ãƒ†ã‚¹ãƒˆ3: åŸºæœ¬GitHub Issueä½œæˆ
    print("\nğŸš€ ãƒ†ã‚¹ãƒˆ3: åŸºæœ¬GitHub Issueä½œæˆ")
    result3 = await test_llm_github_issue_creation()
    results.append(("åŸºæœ¬Issueä½œæˆ", result3))
    
    # æœ€çµ‚çµæœ
    print("\n" + "="*60)
    print("ğŸ“Š E2Eãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    for test_name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"   {test_name}: {status}")
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    print(f"\nğŸ¯ ç·åˆçµæœ: {passed}/{total} ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    
    if passed == total:
        print("ğŸ‰ å…¨ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("   LLMçµŒç”±ã§ã®MCP GitHub toolsçµ±åˆãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
    else:
        print("âš ï¸  ä¸€éƒ¨ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        print("   ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦å•é¡Œã‚’è§£æ±ºã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    asyncio.run(main())
